---
title: 【Robot+LLM】Robot+LLM 研究方向调研综述
date: 2025-12-03 14:00:00 +0800
categories: [LLM,Robot Grasp]
tags: [Robot, LLM]
description: 大模型驱动的机器人抓取研究综述：感知、决策与控制的范式转变 (2024-2025)
mermaid: true
math: true
---

# 1. 引言：具身智能与机器人抓取的“物理AI”时刻

机器人抓取（Robotic Grasping）作为具身智能（Embodied AI）中最基础也最具挑战性的交互能力之一，正在经历一场前所未有的范式转变。在2023年之前，该领域主要由基于几何分析的解析法（Analytic Methods）和基于深度学习的专用模型（如GraspNet, DexNet）主导，这些方法虽然在特定数据集上表现优异，但在面对非结构化环境、语义模糊指令以及长程任务规划时，往往表现出极其有限的泛化能力 。   

进入2024年至2025年，随着大语言模型（LLMs）和视觉-语言模型（VLMs）的爆发式增长，机器人研究正式迈入了“物理AI”（Physical AI）的新纪元。这一阶段的核心特征不再是单纯地训练一个抓取检测网络，而是构建能够理解物理世界常识、进行因果推理并直接生成控制动作的“基础模型”（Foundation Models）。通过将互联网规模的语义知识与机器人轨迹数据相结合，Vision-Language-Action (VLA) 模型和生成式抓取策略（Generative Grasping）彻底改变了机器人“看”、“想”和“动”的方式。   

在这篇博客中将深入探讨大模型如何重构抓取系统的各个环节：从基于开放词汇（Open-Vocabulary）的语义感知，到基于思维链（Chain-of-Thought）的任务规划，再到基于扩散模型（Diffusion Models）的动作生成。综合分析了超过160篇前沿文献，重点关注OpenVLA、RDT-1B、RT-H等标志性工作，以及SynGrasp-1B、GraspClutter6D等新兴的大规模数据集，揭示了从“专用抓取网络”向“通才抓取智能体”演进的技术路径。

# 2. 端到端视觉-语言-动作（VLA）模型架构

在2024-2025年期间，机器人抓取领域最显著的技术跃迁是视觉-语言-动作（VLA）模型的兴起。传统的抓取管线通常是模块化的——先检测物体，再估计6D位姿，最后规划路径。而VLA模型试图通过一个统一的神经网络，直接将多模态输入（图像、文本指令、本体感知）映射为机器人的低层控制信号。这种端到端的范式利用了Transformer架构强大的序列建模能力，使得机器人能够展现出惊人的零样本（Zero-shot）泛化能力。

## 2.1 OpenVLA：开源社区的通用抓取基座
OpenVLA  代表了当前开源VLA模型的最高水平，它的出现打破了Google RT-2等闭源模型的技术垄断。OpenVLA是一个拥有70亿参数的VLA模型，其核心设计理念是通过大规模数据的微调（Fine-tuning）将预训练的视觉-语言模型（VLM）转化为机器人控制策略。   

### 2.1.1 “棱镜”架构与视觉特征融合
OpenVLA建立在Prismatic VLM架构之上，其独特之处在于视觉编码器的双流融合策略。传统的VLM往往在空间分辨率和语义理解之间存在权衡，而OpenVLA通过融合两个异构的视觉骨干网络解决了这一问题：

DINOv2 (ViT-L/14)： 这是一个自监督学习的视觉Transformer，擅长捕捉低层次的几何特征和空间关系。在抓取任务中，DINOv2对于精确识别物体的边缘、接触点以及空间位置至关重要。

SigLIP (So400m)： 这是一个对比学习模型，类似于CLIP但针对图像-文本对齐进行了优化。SigLIP提供了丰富的高层语义特征，使机器人能够理解“抓取那个红色的、看起来像苹果的玩具”这类复杂的语义指令 。   

这种视觉特征的融合通过一个两层的MLP投影器映射到Llama 2 7B语言模型的嵌入空间中。这意味着，对于OpenVLA而言，图像块（Patches）和文本指令（Tokens）在特征空间中是统一的，为后续的跨模态推理奠定了基础。

### 2.1.2 动作离散化与标记化
OpenVLA的一个核心争议点在于其动作表示方式。在v1版本中，模型采用了**动作离散化（Action Discretization）**策略。具体的，机器人的连续动作空间（如末端执行器的7自由度位姿：x, y, z, roll, pitch, yaw, gripper）被量化为256个离散的区间（Bins）。这样一来，预测物理动作就转化为了一个标准的文本生成任务——模型预测一系列代表动作维度的Token，而非直接回归连续数值。这种设计使得OpenVLA能够直接复用Llama 2在大规模文本数据上预训练得到的强大的序列建模能力 。   

然而，离散化也带来了精度损失和控制不平滑的问题。为了解决这一局限，2025年发布的OpenVLA-OFT (Optimized Fine-Tuning) 版本引入了重大的架构调整。OFT摒弃了纯粹的离散化输出，转而在模型末端引入了L1回归头（Regression Head），直接预测连续的动作值。实验表明，这种结合了LLM推理能力与回归头精细控制的混合架构，在LIBERO等仿真基准测试中，将推理速度提升了25-50倍，同时任务成功率提高了20%以上。 

| 特性 | OpenVLA (v1) | OpenVLA-OFT (2025) | RT-2-X |
| --- | --- | --- | --- |
| 基础模型 | Llama 2 7B | Llama 2 7B | PaLM-E / PaLI-X |
| 视觉编码器 | DINOv2 + SigLIP | DINOv2 + SigLIP | ViT-22B / PaLI |
| 动作表示 | 离散Token (256 bins) | 连续回归 (L1 Loss) | 离散Token |
| 推理速度 | 较慢 (自回归生成) | 极快 (25-50x 提升) | 较慢 |
| 主要优势 | 语义理解强，开源 | 精度高，实时性好 | 泛化能力强，闭源 |

## 2.2 RDT-1B：解决双臂协同与多模态分布
在单臂抓取任务中，动作往往是确定的。但在双臂协同（Bimanual Manipulation）场景下，动作分布呈现出显著的多模态性（Multimodality）。例如，面对一个大箱子，机器人既可以用左手抓左边，也可以用右手抓右边，或者双手同时抓取。传统的自回归模型（如OpenVLA v1）倾向于对训练数据中的多种可能性取平均值，导致生成的动作可能是“双手都伸向中间”，从而引发灾难性的失败。

针对这一痛点，清华大学与MIT团队在2024年底推出了RDT-1B (Robotics Diffusion Transformer) 。   

### 2.2.1 扩散变换器（Diffusion Transformer）作为策略头
RDT-1B放弃了Token预测，转而采用**扩散模型（Diffusion Model）**作为策略生成器。该模型基于DiT（Diffusion Transformer）架构，拥有12亿参数。其工作原理是通过迭代去噪（Denoising）的过程，从高斯噪声中恢复出具体的动作序列。 扩散模型的最大优势在于它能够显式地建模复杂的、非凸的动作分布。在推理时，RDT-1B不是输出一个“平均动作”，而是采样出一种具体的、自洽的动作模式（Mode）。这对于双臂协调至关重要，因为它确保了左右臂的动作在时空上是高度耦合且逻辑一致的 。   

### 2.2.2 物理可解释的统一动作空间
为了在包含不同构型机器人的大规模数据集（46个数据集，100万+条轨迹）上进行预训练，RDT-1B提出了物理可解释统一动作空间（Physically Interpretable Unified Action Space）。现有的跨具身（Cross-Embodiment）学习方法通常将动作抽象为隐向量，丢失了物理意义。而RDT-1B将所有机器人的动作映射到一个统一的运动学空间中，保留了速度、力矩等物理属性。这种设计使得模型能够学习到跨平台的通用物理规律（如“重力补偿”、“摩擦力利用”），从而实现了在ALOHA双臂机器人上的零样本迁移 。   

## 2.3 GraspVLA：合成数据与思维链的融合
数据的稀缺性始终是制约VLA模型发展的瓶颈。2025年提出的GraspVLA  探索了一条不同的路径：利用大规模合成数据来训练抓取基础模型。


### 2.3.1 SynGrasp-1B与渐进式动作生成
GraspVLA依托于一个名为SynGrasp-1B的十亿级合成抓取数据集。该数据集通过光线追踪渲染和高保真物理仿真生成，包含了数万种物体在各种极端光照、透明度条件下的抓取数据。 为了弥补合成数据（Sim）与真实世界（Real）之间的鸿沟，GraspVLA引入了**渐进式动作生成（Progressive Action Generation, PAG）**机制。这是一种嵌入在网络内部的视觉思维链（Visual Chain-of-Thought）。模型并不直接从图像生成动作，而是被强制要求先生成中间的感知结果——例如，先预测物体的分割掩码（Mask），再预测深度图，最后才通过流匹配（Flow Matching）生成抓取动作。这种分步生成的策略迫使模型在做出决策前先“看懂”场景，显著提高了Sim-to-Real的稳定性，尤其是在抓取透明物体（如玻璃杯）时表现出了超越传统深度相机的能力 。   

# 3. 开放词汇的可供性感知与语义接地
在传统的机器人抓取中，“感知”往往等同于“物体检测”（Object Detection）。然而，随着大模型的引入，感知的内涵已经扩展为可供性接地（Affordance Grounding）。机器人不仅需要知道“杯子在哪里”，更需要知道“杯子的哪个部位可以被抓取以完成喝水的动作”。这种从“名词理解”到“动词理解”的转变，是实现开放世界抓取的关键。

## 3.1 3DAffordSplat：基于高斯溅射的精细化感知
现有的点云分割方法在处理稀疏数据时往往难以捕捉物体的精细几何特征（如刀刃与刀背的区别）。3DAffordSplat  创新性地引入了**3D高斯溅射（3D Gaussian Splatting, 3DGS）**作为可供性推理的底层表征。   

连续场与语义对齐： 3DGS将场景表示为一系列各向异性的高斯球体。这种表示既保留了连续的几何结构，又携带了高保真的视觉纹理信息。AffordSplatNet模型利用这种特性，设计了一个“粒度自适应选择”（Granularity-Adaptive Selection）模块。当用户指令需要精细操作（如“捏住针头”）时，模型会自动聚焦于高曲率、小尺度的高斯球；当指令涉及粗略操作（如“抱起玩偶”）时，模型则聚合大尺度的高斯球。

跨模态结构对齐： 该研究还提出了跨模态结构对齐（CMSA）机制，利用对比学习将点云的几何特征与3DGS的视觉特征拉齐。实验证明，这种方法在识别“未见过的物体部件”（Unseen Object Parts）时，其IoU（交并比）显著优于传统的PointNet++或体素化方法 。   

## 3.2 AnyPart：模块化基础模型的组合威力
与端到端的VLA不同，AnyPart  展示了另一种高效的技术路线：模块化组合（Composability）。该框架的核心洞察是：我们不需要为了抓取而重新训练一个大模型，而是可以将现有的最强SOTA模型像积木一样串联起来。   

工作流：

检测（Detection）： 使用GroundingDINO等开放词汇检测器，根据文本（如“红色的马克杯”）定位物体边界框。

分割（Segmentation）： 利用SAM（Segment Anything Model）或VLPart，在边界框内根据部件指令（如“把手”）分割出精确的掩码。

抓取合成（Grasp Synthesis）： 将分割后的点云输入到针对局部几何优化的抓取生成网络中，仅在掩码区域内采样抓取位姿。

性能与效率： 这种方法的优势在于极高的灵活性和无需训练。如果明天出了一个更强的分割模型（如SAM 2），AnyPart可以直接替换模块从而获得性能提升。实验数据显示，AnyPart在复杂的杂乱场景中实现了60.8%的抓取成功率，且推理速度比Lerf-TOGO等基于NeRF的方法快了60倍 。   

## 3.3 AffordanceLLM：大模型的世界知识注入
AffordanceLLM  探讨了如何将大语言模型中蕴含的隐式世界知识显式地转化为机器人的感知能力。   

嵌入即一可供性（Embedding as Affordance）： 该模型并没有从头学习什么是“骑”，而是微调了一个多模态大模型（LMM），使其能够输出一个特殊的 <affordance> Token。这个Token通过一个专用的解码器映射为图像上的热力图。

常识推理： 利用LLM的预训练知识，AffordanceLLM能够解决反直觉的抓取问题。例如，对于“递给我这把刀”的指令，传统的几何方法可能会建议抓取刀刃（因为那里平坦好抓），但AffordanceLLM结合了“递刀不能伤人”的常识，会高亮刀柄作为可供性区域，甚至能推断出“刀尖朝下”的姿态约束。这种基于常识的推理是传统几何抓取无法企及的 。


## 3.4 VCoT-Grasp：视觉思维链与多轮推理
在极度杂乱的场景中（如堆满零件的盒子），单次的前向推理往往会因为背景干扰而失败。VCoT-Grasp  引入了**视觉思维链（Visual Chain-of-Thought）**的概念，模拟人类“先粗看、再细看、后决策”的认知过程。   

多轮推理机制：

全局定位： 模型首先根据指令“抓取红色标记笔”，在全图范围内预测一个粗略的边界框。

视觉缩放（Visual Zoom）： 系统将图像裁剪到该边界框并放大，去除背景噪声。

局部推理： 在高分辨率的局部视图中，VLM重新分析物体的姿态、遮挡关系以及具体的抓取点。

动作生成： 最后生成的抓取位姿会被逆投影回全局坐标系。

效果： 这种“思考-观察-再思考”的机制显著提升了小物体和遮挡物体的抓取成功率。在包含20个以上物体的密集堆叠场景中，VCoT-Grasp相比于无递归的基线模型，成功率提升了12%以上。

4. 决策与规划：从动作执行到层级推理
单纯的抓取动作（Action）只是任务的一环。要完成“整理房间”或“装配零件”等长程任务，机器人需要具备高层的决策与规划能力。2024-2025年的研究热点是如何将大语言模型的逻辑推理能力（System 2）与机器人的运动控制能力（System 1）有机结合。

4.1 RT-H：构建“动作的语言”
RT-H (Robotic Transformer - Hierarchical)  提出了一种层级化的学习架构，旨在解决抽象指令与底层控制之间的语义鸿沟。   

中间层表征： RT-H并不直接从“把可乐拿给我”映射到关节力矩，而是先预测一系列中间层的“语言动作”（Language Motions），如“向前移动手臂”、“向右旋转手腕”、“闭合夹爪”。这些短语构成了机器人动作的“词汇表”。

数据共享与纠错： 这种层级结构允许不同任务之间共享数据。例如，“拿苹果”和“倒水”任务可能都包含“向前移动手臂”这一子动作。更重要的是，这种设计支持自然语言纠错。如果机器人执行出错，人类可以直接喊出“不，抬高一点”，RT-H能够理解这一语言动作并实时修正策略，而无需重新编程 。   

## 4.2 Code-as-Monitor：代码作为监控者
在开放世界中，失败是不可避免的。如何让机器人意识到自己“搞砸了”？Code-as-Monitor (CaM)  利用大模型强大的代码生成能力（Code Generation），构建了一个实时的故障检测系统。   

约束感知可视化编程： 当接收到任务（如“端着装满水的杯子移动”）时，CaM会调用GPT-4o生成一段Python监控代码。这段代码不仅仅是逻辑判断，它还会调用视觉API（如VLM或分割模型）来实时检查物理约束。

反应式与前瞻式检测：

反应式（Reactive）： 检测到杯子倾斜角度超过阈值（通过视觉API返回的数值），立即停止机械臂。

前瞻式（Proactive）： 在抓取前，代码会检查路径上是否有障碍物移动到了危险区域，从而预防碰撞。

实验结果： CaM不仅提高了系统的鲁棒性，还使得机器人能够在没有明确失败数据训练的情况下，通过逻辑代码实现自我监督。实验显示，在动态干扰环境下，CaM将任务成功率提升了28.7% 。   

## 4.3 GLOVER与AGE：泛化可供性推理
GLOVER  进一步整合了感知与规划。它不仅仅输出一个抓取点，而是输出一个任务相关的可供性场（Affordance Field）。   

Affordance-Aware Grasping Estimation (AGE)： GLOVER的核心创新在于其下游规划器AGE。AGE是一个非参数化的优化算法，它接收GLOVER预测的可供性掩码，并基于超二次曲面（Superquadric Surface）拟合，计算出既符合几何约束（不碰撞）又符合语义约束（抓在把手上）的最佳抓取位姿。这种将深度学习推理（GLOVER）与几何优化（AGE）解耦的设计，使得系统在面对未见过的物体形状时具有极强的鲁棒性 。   

# 5. 生成式抓取：扩散模型与流匹配
传统的抓取检测通常被建模为分类或回归问题（即预测抓取质量得分最高的候选框）。然而，抓取位姿的分布本质上是连续且多模态的。2024-2025年，**生成式AI（Generative AI）**技术，特别是扩散模型（Diffusion Models），开始统治高性能抓取算法领域。

5.1 GraspLDM：潜在空间中的抓取生成
直接在三维空间或像素空间进行扩散生成的计算成本极高，难以满足机器人实时的要求。GraspLDM  巧妙地将生成过程转移到了潜在空间（Latent Space）。   

VAE压缩： 首先，训练一个变分自编码器（VAE），将复杂的6-DoF抓取位姿和物体点云压缩成低维的潜在向量。

潜在扩散（Latent Diffusion）： 然后，在潜在空间中训练一个轻量级的扩散模型。该模型学习的是“什么样的潜在向量代表一个好的抓取”。

生成过程： 在推理时，模型从随机噪声开始，在潜在空间进行去噪，最后通过VAE解码器还原为物理抓取位姿。这种方法不仅速度极快（毫秒级），而且能够生成极其多样化的抓取姿态（例如，针对一个电钻，它可以生成抓手柄、抓电池包等多种合理的抓取方式），且在真机测试中达到了80%的成功率 。   

5.2 HGDiffuser：引导式采样与任务约束
扩散模型的一个潜在问题是它生成的抓取可能是“物理上稳定”但“任务上无用”的（例如抓住了刀刃）。HGDiffuser  引入了**引导式采样（Guided Sampling）**机制。   

分层引导： 在扩散模型的去噪步骤中，HGDiffuser不仅考虑数据分布的梯度（Score Function），还加入了一个由任务约束定义的梯度场（Guidance Gradient）。

应用： 比如任务是“切菜”，约束函数会惩罚那些使得刀刃被遮挡的抓取姿态。这个梯度会引导扩散过程“漂移”向刀柄区域。这样生成的抓取天然满足任务需求，无需后处理过滤。这一技术标志着抓取生成从“无条件生成”向“可控生成”的演进 。