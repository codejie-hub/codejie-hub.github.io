LoRA 微调 和 QLoRA 基础了解
讲解参考
[图片]
核心基于矩阵分解，1024*512的矩阵可以拆解成两个矩阵 1024*32 ，32*512。

处理的优点：
原始矩阵的参数量：1024*512=524288
分解的两个矩阵参数量：1024*32(32768)  +  32 * 512(16384 ) = 49152
分解后的矩阵参数量只占原矩阵参数量的 9% ，用9% 的参数量来表征原始特征分布。

参数矩阵如何更新？
假设原来的参数矩阵 $$W_q$$ shape : 1024 * 512 , 原来模型的参数不去更新，而是通过更新两个分解的两个小矩阵的参数，然后通过两个小矩阵进行反解得到和原参数矩阵 $$W_q$$相同尺寸的矩阵，再与原模型的参数进行相加。

LoRA 如何做的计算？
[图片]

初始化
[图片]
超参数：影响训练微调时的学习率
- $$\alpha$$:  缩放因子，用于在训练时调节 ΔW的大小
- $$r$$:  低秩分解的维度。
     当 r 较小 → 参数量少，微调更轻量，但表达能力有限；
     当 r 较大 → 适配能力增强，但参数量和计算量也随之增加。
举例：如果原始权重是 4096×4096，设置 r=8，那么只需学习 4096×8+8×4096 ≈ 6.5万参数，远小于原始的 1600万参数。
- $$\frac{\alpha}{r}$$: 
     - 避免 r 不同导致参数规模不一致时训练不稳定；
     - 通过 α/r 归一化，使得不同 r 设置下，ΔW的更新幅度在一个合理范围
α/r 越大，LoRA 注入模型的影响越强；
α/r 越小，越接近零更新，适配效果弱。

---
简单应用
[图片]

量化LoRA
降低模型计算精度，加快计算速度，减少GPU内存消耗。
[图片]
